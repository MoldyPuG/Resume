## 職務要約

2022年4月より、株式会社FLINTERS BASEでデータエンジニアとして入社後、LINE株式会社（現LINEヤフー株式会社）へ派遣社員として配属されました。

配属後は、PythonやAzkaban、Airflowを利用したELTパイプラインのメンテナンスや、SparkSQLを用いたビッグデータの処理などに従事。
中央組織のデータチームの一員として、事業部側のエンジニアやビジネスサイドのステークホルダーと緊密に連携しながら、クリーンなデータセットの提供や事業に必要なデータの提供に努めてきました。

## 言語経験・スキル

| Category | Name |
| :------ | :------ |
| 開発手法 | アジャイル |
| 言語 | Python / SQL |
| フレームワーク等 | Query Engine - Spark / Hive <br> Workflow Tool - Airflow / Azkaban <br> Distributed Framework - Hadoop <br> Table Format - Iceberg <br> Code Management - Github|

## 職務経歴詳細

### 株式会社FLINTERS BASE

- 事業内容: データエンジニア派遣・データ人材育成
- 資本金: 50,000,000円
- 従業員数: 43名（2024年1月1日現在）
- URL: <https://www.flinters-base.co.jp>

#### LINE株式会社（現LINEヤフー株式会社）配属

【 雇用形態 】

- 正社員（派遣社員としてLINE株式会社勤務）

【 在籍期間 】

- 2022/04/01 ~ 現在

【 職種・役割 】

- データエンジニア・メンバー

【 職務内容 】

- 概要：ELTパイプラインを利用したデータの処理やユーザビリティの高いデータの提供に従事しています

### 主な参画したプロジェクトやタスク

#### ① 合併に際する会社間データ連携プロジェクト

* * *

【 期間 】2023年8月〜2023年11月 <br> 
【 担当フェーズ 】Table定義設計、実装、単体テスト、運用保守 <br>
【 業務内容 】

- Table Designの作成
- Queryの実装・テスト
- 運用・保守メンテナンス

【 実績・取り組み 】

- メンバーとして、リーダー、PMと3名で開発（プロジェクト全体の規模感としては15名ほど）
- 社外、社内の様々なステークホルダーと円滑に連携しながら、要件に沿ってTableスキーマを作成
- ビジネスロジックを意識しながらの実装に加え、実行時間やデータサイズによる負荷を考慮しながらバッチジョブを作成

【 利用技術 】 Spark / Airflow

#### ② 定期実行バッチジョブの実行速度改善

* * *


【 期間 】2023年5月〜2023年8月 <br> 
【 担当フェーズ 】調査、実装、テスト <br> 
【 業務内容 】

- HDFSに作成されたsmall fileがバッチジョブの実行時間の増加に及ぼす問題の調査
- 上記問題を解決するためにQuery Logicを修正
  
【 実績・取り組み 】

- 数千から1万程度のsmall fileが作成されており、各パーティションへの書き込みの時間が数時間以上増加していた
- データを生成するSparkSQLの中で、Query Hintを用いることにより、ファイルを数十個程度にコンパクションし、生成時間も1時間半程度に改善
- 同様の事例が他の場所でも起こっていたため、ドキュメントを整理して横展開を行った

【 利用技術 】Spark / Haddop（HDFS）

#### ③ 利用されていないテーブルの検知と自動削除を行うJobを作成

* * *

【 期間 】2023年11月〜2024年1月 <br>
【 担当フェーズ 】要件定義、設計、実装、テスト、運用・保守 <br>
【 業務内容 】

- データ保有コスト削減のため、自分達が所有する開発用DB内に存在する利用されていないTableを検知し、自動的に削除を行うJobを作成
- Jobの要件定義から実装、その後の運用保守まで担当

【 実績・取り組み 】

- 作成されてから一定の期間使われていないTableをHDFSファイルのUpdated Timeを利用して抽出し、Slackでユーザーにメンションする機能の実装
- その後、更新やホワイトリストへの退避がない場合、自動的に削除を行う機能を実装
- 最終的に2021年以降放置されていた約300の開発用Tableの削除及び2TB程度のリソースの削減を達成した

【 利用技術 】Python / Spark (Pyspark) / Airflow / HDFS

#### ④ ユーザー影響の大きいデータを処理するテーブルのスキーマ変更

* * *

【 期間 】2022年7月〜2022年10月 <br>
【 担当フェーズ 】Tableスキーマ再設計、実装、テスト、運用・保守 <br>
【 業務内容 】

- ユーザーニーズを満たすためのパーティションカラムを追加するため、新しいスキーマのTable作成、データ生成とユーザーの移行サポート

【 実績・取り組み 】

- リーダーと壁打ちしながらのスキーマの再設計及び、バッチジョブの作成とテストを行う
  - 日次で数TB規模のデータを処理するため、Queryのロジックに気を配りながらJobを作成した
- 数十のTableをDownstreamに持つコアテーブルのため、関連するステークホルダーとやりとり、移行の影響調査を行いながらサポートを行った

【 利用技術 】 Python / Azkaban / Hive

#### ⑤ レガシーELTパイプラインの廃止プロジェクト

* * *

【 期間 】2022年7月〜2023年8月 <br>
【 担当フェーズ 】運用保守 <br>
【 業務内容 】

- ユーザーがデータをセルフサーブしていくという目的を基に、ユーザーが手軽に利用できる新しいバッチパイプラインの運用が開始されたため、過去にデータチームが一元管理していた古いバッチパイプラインの廃止を行なった

【 実績・取り組み 】

- 多くのステークホルダーと緊密にやりとりをしながらバッチジョブの移管のサポートを行なった
- 既存のバッチパイプラインで運用されているジョブを逐一削除していたため、まだ稼働している他のサービスへの影響がないかの調査、テストを綿密に実行した
- 最終的に30を超えるバッチジョブの停止を完遂し、レガシーパイプラインを廃止した

【 利用技術 】Python / Azkaban / Hive / MySQL

## 自己PR

日々、ユーザーが手軽かつ安全にデータを利用できるよう、データエンジニアおよびアナリティクスエンジニアとして活動しています。

一つのサービス事業部の中ではなく、中央組織のデータチームに所属しているため、常に様々なステークホルダーと連携をしながら業務を遂行しています。
また、上記のいくつかの職務経歴に挙げたような、テラバイト規模のデータや広範囲のユーザーに影響を与えるデータを取り扱うため、ジョブの修正や作成を行う際には、どんな影響を及ぼすかを常に意識しながらデータの生成や実装を行っています。

参加したプロジェクトでは、SQLを使用し、多くのステークホルダーと協力してビジネスに価値をもたらすデータを生成できたことは自分にとって興味深い経験であり、今後は、さらにビジネスサイドに近づき、貢献していきたいとも考えています。
また、データモデリングやデータマネジメントの理論を学び、ボトムアップのアプローチだけでなく、組織やデータパイプライン全体を俯瞰して課題を把握し、解決に取り組むことで、より優れたデータプロフェッショナルを目指しています。
