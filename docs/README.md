## 職務要約

2022年4月より、株式会社FLINTERS BASEでデータエンジニアとして入社後、LINE株式会社（現LINEヤフー株式会社）へ派遣社員として配属されました。

配属後は、PythonやAzkaban、Airflowを利用したELTパイプラインのメンテナンスや、SparkSQLを用いたビッグデータの処理などに従事。
中央組織のデータチームの一員として、事業部側のエンジニアやビジネスサイドのステークホルダーと緊密に連携しながら、クリーンなデータセットの提供や事業に必要なデータの提供に努めてきました。

## 言語経験・スキル

| Category | Name |
| :------ | :------ |
| 開発手法 | アジャイル |
| 言語 | Python (2 years) / SQL (2 years) |
| フレームワーク等 | **Query Engine** - Spark (2 years) / Hive (2 years) <br> **Workflow Tool** - Airflow (1.7 years)/ Azkaban (1 years) <br> **Distributed Framework** - Hadoop (2 years) <br> **Table Format** - Iceberg (0.5 years) <br> **Code Management** - Github (2 years)|

## 職務経歴詳細

### 株式会社FLINTERS BASE

- 事業内容: データエンジニア派遣・データ人材育成
- 資本金: 50,000,000円
- 従業員数: 49名（2024年4月時点）
- URL: <https://www.flinters-base.co.jp>

#### LINE株式会社（現LINEヤフー株式会社）配属

【 雇用形態 】

- 株式会社FLINTERS BASE 正社員勤務（派遣社員としてLINE株式会社配属）

【 在籍期間 】

- 2022/04/01 ~ 現在

【 職種・役割 】

- データエンジニア・メンバー

【 職務内容 】

- 概要：ELTパイプラインを利用したデータの処理やユーザビリティの高いデータの提供に従事しています

### 主な参画したプロジェクトやタスク

#### ① 合併に際する会社間データ連携プロジェクト

* * *

【 期間 】2023年8月〜2023年11月 <br> 
【 業務内容 】
- 概要 
  - 両会社間で合併直後からのスムーズなデータ連携を図るため、テラバイト規模のデータを含む、必要なデータをSparkSQLを用いて、処理、変形しテーブルを作成。バッチパイプラインを通じてのデータ転送までを行った
- 担当した業務項目
  - 関係者間での要件定義
  - 上記に基づく、Table Designの設計
  - Queryの実装・テスト
  - 運用・保守メンテナンス

【 実績・取り組み 】

- メンバーとして、リーダー、PMと3名で開発（プロジェクト全体の規模感としては15名ほど）
- 社外、社内の様々なステークホルダーと円滑に連携しながら、要件の整理や提供するデータ項目の整理を行う
- 10月合併直後のリリースまで期限が迫る中で、8月末から9月末までに実装、テストを行い、本番環境のリリースまでを完遂
- ビジネスロジックを意識しながらの実装に加え、実行時間やデータサイズによる負荷を考慮しながらバッチジョブを作成

【 利用技術 】 Spark / Airflow / AWS S3

#### ② 定期実行バッチジョブの実行速度改善

* * *


【 期間 】2023年5月〜2023年8月 <br> 
【 業務内容 】
- 概要
  - データ生成時に作成される、HDFS上のsmall fileが、NameNodeのメモリ使用率を逼迫し、バッチジョブの実行時間が長くなっていた問題を解決した
- 担当した業務項目
  - 問題の原因調査
  - 修正項目の適用方法を設計
  - 実装・テスト
  
【 実績・取り組み 】

- 数千程度のsmall fileが毎日作成されており、各パーティションへの書き込みの時間が通常より5時間以上増加している日が続いていたのを、データを生成するSparkSQLの中で、Query Hintを用いることにより、ファイルを数十個程度にコンパクションし、生成時間も1時間半程度に改善した
- 同様の事例が他の場所でも起こっていたため、ドキュメントを整理して横展開を行った

【 利用技術 】Spark / Haddop（HDFS）/ Airflow

#### ③ 利用されていないテーブルの検知と自動削除を行うJobを作成

* * *

【 期間 】2023年11月〜2024年1月 <br>
【 業務内容 】
- 概要
  - ストレージ利用コスト削減のため、自分達が所有する開発用DB内に存在する利用されていないTableを検知し、アラートおよび自動的に削除を行うアプリケーションを作成
- 担当した業務項目
  - 要件定義
  - 設計
  - 実装
  - メンテナンス・運用

【 実績・取り組み 】

- 作成されてから一定の期間使われていないTableをHDFSファイルのUpdated Timeを利用して抽出し、Slackでユーザーにメンションする機能の実装
- その後、更新やホワイトリストへの退避や利用がない場合、一定期間後に自動的に削除を行う機能を実装
- 最終的に2021年以降放置されていた約300の開発用Tableの削除及び2TB程度のリソースの削減を達成した

【 利用技術 】Python / Spark (Pyspark) / Airflow / HDFS

#### ④ ユーザー影響の大きいデータを処理するテーブルのスキーマ変更

* * *

【 期間 】2022年7月〜2022年10月 <br>
【 業務内容 】
- 概要
  - 日次でテラバイト規模のデータを持ち、300人以上のユーザーが利用するテーブルに対して、適切なアクセスコントロールのため、各国におけるユーザーが自分の国のデータを利用できるように、パーティションカラムを追加した新しいテーブルを生成
- 担当した業務項目
  - 要件定義
  - 設計（Tableスキーマおよびデータ生成を行うバッチジョブ）
  - 実装
  - メンテナンス・運用

【 実績・取り組み 】

- 影響範囲が広いテーブルに対して、関連するステークホルダーとやりとり、移行の影響調査、サポートを行いながら実装までを完遂した
- データサイズが大きいため、実装時のロジックやINSERT OVERWRITEの方法などテストを重ねながら実行時間やコンピューティングリソースを少なくすることを心がけた

【 利用技術 】 Python / Azkaban / Hive

#### ⑤ レガシーETLパイプラインの廃止プロジェクト

* * *

【 期間 】2022年7月〜2023年8月 <br>
【 業務内容 】
- 概要
  - ユーザーが自分達の利用するデータをセルフサーブしていくという目的を基に、ユーザーが手軽に利用できる新しいバッチパイプラインの運用が開始されたため、過去にデータチームが一元管理していた古いバッチパイプラインの廃止を行なった
- 担当した業務項目
  - 既存のデータ基盤の保守・運用

【 実績・取り組み 】

- 多くのステークホルダーと緊密にやりとりをしながら、日頃のデータ生成に影響を及ぼさないように運用していた
- 最終的に30を超えるバッチジョブの停止を完遂し、レガシーパイプラインを廃止した

【 利用技術 】Python / Azkaban / Hive / MySQL

### Leverages 株式会社

- 事業内容:メディア事業; 人材関連事業; システムエンジニアリング事業; M&Aコンサルティング事業
- 従業員数:1200名(正社員)
- 資本金:5,000万円
- 売上高:561億(2020年度)

【 雇用形態 】

- 正社員

【 在籍期間 】

- 2021/04/01 ~ 2021/09/30

【 職種・役割 】

- Career / Recruit Advisor

【 職務内容 】

- 介護業界における人材紹介営業として、6ヶ月間勤務していました

### 主な参画したプロジェクトやタスク

#### 介護士のCareer Advisorおよび、介護施設のRecruiting Advisor

第2四半期(7月~9月)売上実績:約450万円(目標指数120%達成)
常に毎日の数字の変化を意識して営業を行うことで、上記結果を達成いたしました。

求職者の選択肢が少ないのか、面接に行ける数が少ないのか、合格できないのかなど、可視化された数値の中で今の自分がどういう行動を取るべきかを常に考え、取り組んでおりました。
その中でも求職者に多くの選択肢を与えるべく、求職者への施設提案率を特に意識して企業側へ求職者採用時のメリット訴求を続けた結果、目標数値60%に対して70%の提案率を達成し、上記結果へ結びつけました。
また、施設へのヒアリングで得た情報をチームへ共有、蓄積し見える化していくことで、チームの売上達成や、チームメンバーの求職者の機会損失減少へ貢献しました。

## 自己PR

日々、ユーザーが手軽かつ安全にデータを利用できるよう、データエンジニアとして活動しています。

一つのサービス事業部の中ではなく、中央組織のデータチームに所属しているため、常に様々なステークホルダーと連携をしながら業務を遂行しています。
また、上記のいくつかの職務経歴に挙げたような、テラバイト規模のデータや広範囲のユーザーに影響を与えるデータを取り扱うため、ジョブの修正や作成を行う際には、どんな影響を及ぼすかを常に意識しながらデータの生成や実装を行っています。

参加したプロジェクトでは、SQLを使用し、多くのステークホルダーと協力してビジネスに価値をもたらすデータを生成できたことは自分にとって興味深い経験であり、今後は、さらにビジネスサイドに近づき、貢献していきたいとも考えています。
また、データモデリングやデータマネジメントの理論を学び、ボトムアップのアプローチだけでなく、組織やデータパイプライン全体を俯瞰して課題を把握し、解決に取り組むことで、より優れたデータプロフェッショナルを目指しています。

普段LINEヤフー株式会社では、オンプレミスのシステムでデータ基盤が構築されているため、クラウドを利用した開発に携わることは少ないですが、その中でも自分でAWS GlueやRedshiftなどを利用してみたり、知識の整理のためにAWS Developer Associateの資格の取得など積極的に技術のキャッチアップに動いています。

dbtやdagsterなど様々なモダンなテックスタックにも自分で今後触りながら、データエンジニアとしてより自分の力を高めていければと思っています。
